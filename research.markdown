---
layout: default
permalink: /research/
---

{% include nav.html %}

## Research

Find us on [Github](https://github.com/Algorithmic-Alignment-Lab).


### 2024

#### Papers

Sheshadri, A., Ewart, A., Guo, P., Lynch, A., Wu, C., Hebbar, V., Sleight, H., Cooper Stickland A., Perez, E., Hadfield-Menell, D., & Casper, S. (2024). [Targeted Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs.]() arXiv preprint arXiv:2407.15549.[BibTeX](https://arxiv.org/abs/2407.15549)

Casper, S., Yun, J., Baek, J., Jung, Y., Kim, M., Kwon, K., ... & Hadfield-Menell, D. (2024). [The SaTML'24 CNN Interpretability Competition: New Innovations for Concept-Level Interpretability.](https://arxiv.org/abs/2404.02949) arXiv preprint arXiv:2404.02949. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:x4JPMDBv3TgJ:scholar.google.com/&output=citation&scisdr=ClGidL9yEIaMg7yzD8o:AFWwaeYAAAAAZhK1F8rTj_IS5eT03h-duUYWftU&scisig=AFWwaeYAAAAAZhK1F3X_AdsFRCzxa2qeqTA7oco&scisf=4&ct=citation&cd=-1&hl=en)

Casper, S., Schulze, L., Patel, O., Hadfield-Menell, D. (2024) [Defending Against Unforeseen Failure Modes with Latent Adversarial Training](https://arxiv.org/abs/2403.05030) arXiv preprint: ariXiv:2403.05030 [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:epBKB-Umi1MJ:scholar.google.com/&output=citation&scisdr=ClGidL9yEIaMg7yzGbk:AFWwaeYAAAAAZhK1AbkrDvAbxi7MLbnZ3d2H_IQ&scisig=AFWwaeYAAAAAZhK1Adxqs0S_OPGxJ_dqfe0Dy8g&scisf=4&ct=citation&cd=-1&hl=en)

Lynch, A., Guo, P., Ewart, A.*, Casper, S., Hadfield-Menell, D. (2024). [Eight Methods to Evaluate Robust Unlearning in LLMs.](https://arxiv.org/abs/2402.16835) arXiv preprint: ariXiv:2402.16835. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:Ea0aPUr5uVkJ:scholar.google.com/&output=citation&scisdr=ClGidHcwEIaMgEBgWCQ:AFWwaeYAAAAAZe5mQCQ6iaKYzjvpwp75W_fMaUw&scisig=AFWwaeYAAAAAZe5mQE3IhnbAnh6AjPHXsWXKUlU&scisf=4&ct=citation&cd=-1&hl=en)

Casper, S., Ezell, C., Siegmann, C., Kolt, N., Curtis, T., Bucknall, B., Haupt, A., Wei, K., Scheurer, J., Hobbhahn, M., Sharkey, L., Krishna, S., Von Hagen, M., Alberti, S., Chan, A., Sun, Q., Gerovitch, M., Bau, D., Tegmark, M., Krueger, D., Hadfield-Menell, D. (2024) [Black-Box Access is Insufficient for Rigorous AI Audits.](https://arxiv.org/abs/2401.14446) Proceedings of the 2021 ACM conference on fairness, accountability, and transparency. 2024. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:SIgJw-M0K-oJ:scholar.google.com/&output=citation&scisdr=ClGidHcwEIaMgEBgcRc:AFWwaeYAAAAAZe5maRd4xJkKwUDBF4WW2w-7eGo&scisig=AFWwaeYAAAAAZe5maX_sXB_drOinR6kTuVtJK5E&scisf=4&ct=citation&cd=-1&hl=en)


### 2023

#### Papers

Liu, K., Casper, S., Hadfield-Menell, D., Andreas., J. (2023) [Cognitive Dissonance: Why Do Language Model Outputs Disagree with Internal Representations of Truthfulness?](https://arxiv.org/abs/2312.03729) EMNLP, 2023. [BixTex](https://scholar.googleusercontent.com/scholar.bib?q=info:5BycjoRATvEJ:scholar.google.com/&output=citation&scisdr=ClEt6tmSELrotScCUas:AFWwaeYAAAAAZbgESatLgBg16vDIEXl3VefLxy4&scisig=AFWwaeYAAAAAZbgESbnvkMNVJSF7hh-hVtUAyTs&scisf=4&ct=citation&cd=-1&hl=en)

Casper S., Davies, X., Shi, C., Gilbert, T., Scheurer, J., Rando, J., Freedman, R., Korbak, T., Lindner, D., Freire, P., Wang, T., Marks, S., Segerie, C., Carroll, M., Peng, A., Christoffersen, P., Damani, M., Slocum, S., Anwar, U., Siththaranjan, A., Nadeau, M., Michaud, E., Pfau, J., Krasheninnikov, D., Chen, X., Langosco, L., Hase, P., Bıyık, E., Dragan, A., Krueger, D., Sadigh, D., & Hadfield-Menell, D. (2023) [Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2307.15217). arXiv preprint: arXiv:2307.15217. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:RH-S-PbNWxwJ:scholar.google.com/&output=citation&scisdr=ClEwd-8QELrotZK8gUM:AFWwaeYAAAAAZQ26mUOuSmaMoaBbXw5x8Xcd9_c&scisig=AFWwaeYAAAAAZQ26mfH5WdcdIFu_Sqw5gMb1WgY&scisf=4&ct=citation&cd=-1&hl=en).

Yew, R. J. & Hadfield-Menell, D. (2023). [Break It Till You Make It: Limitations of Copyright Liability Under A Pre-training Paradigm of AI Development](https://genlaw.github.io/CameraReady/30.pdf?fbclid=IwAR3kZNuMD4ktqDyIDH_0IdYFn7hDdGVhJ31vIHLr2gi_ZQ8JuRhVtoba7dI). Featured at the first annual Generative AI + Law Workshop at ICML 2023. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:aYUif0qWxs0J:scholar.google.com/&output=citation&scisdr=ClEwd-8QELrotZK8ZzY:AFWwaeYAAAAAZQ26fzYksC9xYIesKNZZFvOJohw&scisig=AFWwaeYAAAAAZQ26f9ap7pAVaIo6_NUe7GsG9b4&scisf=4&ct=citation&cd=-1&hl=en). \*\*\*[Spotlight paper award](https://genlaw.github.io/papers.html#break-it-till-you-make-it-limitations-of-copyright-liability-under-a-pre-training-paradigm-of-ai-development)\*\*\*

Casper, S., Guo, Z., Mogulothu, S., Marinov, Z., Deshpande, C., Yew, R. J., Dai, Z., & Hadfield-Menell, D. (2023). [Measuring the Success of Diffusion Models at Imitating Human Artists](https://arxiv.org/abs/2307.04028). Featured at the first annual Generative AI + Law Workshop at ICML 2023. [BibTeX](Measuring the Success of Diffusion Models at Imitating Human Artists). \*\*\*[Spotlight paper award](https://genlaw.github.io/papers.html#measuring-the-success-of-diffusion-models-at-imitating-human-artists)\*\*\*

Casper, S., Lin, J., Kwon, J., Culp, G., & Hadfield-Menell, D. (2023). [Explore, Establish, Exploit: Red Teaming Language Models from Scratch.](https://arxiv.org/abs/2306.09442) arXiv preprint arXiv:2306.09442. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:rzNKauKCM_QJ:scholar.google.com/&output=citation&scisdr=ClEwd-8QELrotZK8QU0:AFWwaeYAAAAAZQ26WU2CMr9A1UaPA0PZoq0p4pA&scisig=AFWwaeYAAAAAZQ26WWSdwIqH9zq2bj1Pr96KjbE&scisf=4&ct=citation&cd=-1&hl=en).

Zhang, B. H., Farina, G., Anagnostides, I., Cacciamani, F., McAleer, S. M., Haupt, A. A., ... & Sandholm, T. (2023). [Steering No-Regret Learners to Optimal Equilibria.](https://arxiv.org/abs/2306.05221) arXiv preprint arXiv:2306.05221. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:em_edOqxDFUJ:scholar.google.com/&output=citation&scisdr=ClEwd-8QELrotZK8Jng:AFWwaeYAAAAAZQ26PngHalv3kHKFmUIpCSth1xA&scisig=AFWwaeYAAAAAZQ26Pur57wTTkyB-WAMp1Ek9LlM&scisf=4&ct=citation&cd=-1&hl=en).

Zhang, B. H., Farina, G., Anagnostides, I., Cacciamani, F., McAleer, S. M., Haupt, A. A., ... & Sandholm, T. (2023). [Computing Optimal Equilibria and Mechanisms via Learning in Zero-Sum Extensive-Form Games.](https://arxiv.org/abs/2306.05216) Advances in Neural Information Processing Systems, 36. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:At-MfwxtpCcJ:scholar.google.com/&output=citation&scisdr=ClEwd-8QELrotZK8FW4:AFWwaeYAAAAAZQ26DW5X9Vo8YMBQzuulukz-Svg&scisig=AFWwaeYAAAAAZQ26DWMq5gPAi9GjQnH-74KWMg4&scisf=4&ct=citation&cd=-1&hl=en).

Yew, R.J., Curtis, T.L., Leake, M., Podimata, C., Hadfield-Menell, D. (2023). [Policy Paths Toward an Understanding of AI Interfaces: A Case Study on Recommendation Platforms.](https://cornell.app.box.com/s/gtqnbjiial0kzcqcr5awqdfz10hv0c92) 2023 ACM CHI Designing Technology and Policy Simultaneously Workshop. 

Casper, S., Li, Y., Li, J., Bu, T., Zhang, K., Hariharan, K., Hadfield-Menell, D., (2023). [Red Teaming Deep Neural Networks with Feature Synthesis Tools.](https://arxiv.org/abs/2302.10894) Advances in Neural Information Processing Systems, 36. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:BNZOzOIqT1IJ:scholar.google.com/&output=citation&scisdr=ClEwd-8QELrotZK_rXI:AFWwaeYAAAAAZQ25tXK_FhpczacuVjgj86lAWHc&scisig=AFWwaeYAAAAAZQ25tapRK7e3J8ce9czQQNbTS18&scisf=4&ct=citation&cd=-1&hl=en). 

Haupt, A., Hadfield-Menell, D., & Podimata, C. (2023). [Recommending to Strategic Users.](https://arxiv.org/abs/2302.06559) arXiv preprint arXiv:2302.06559. [Bibtex](https://scholar.googleusercontent.com/scholar.bib?q=info:TvVSadb4eCUJ:scholar.google.com/&output=citation&scisdr=ClEwd-8QELrotZK_Dhw:AFWwaeYAAAAAZQ25Fhx27stTN2r6MyhL6Wcwv94&scisig=AFWwaeYAAAAAZQ25Fg4cCekUAhITAKQ5YgtaTio&scisf=4&ct=citation&cd=-1&hl=en).

#### Resources

[Contracts Library](https://github.com/Algorithmic-Alignment-Lab/contracts) for contract-based multiagent RL. Christoffersen, P.J.K., Haupt, A.A, Damani, M.

[CommonClaim Dataset](https://github.com/Algorithmic-Alignment-Lab/CommonClaim) of 20k statements labeled by humans as common-knowledge true, common-knowledge false, and neither. Casper, S., Lin, J., Kwon, J., Culp, G., & Hadfield-Menell, D.

### 2022

#### Papers

Casper, S., Hariharan, K., Hadfield-Menell, D., (2022). [Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks.](https://arxiv.org/abs/2211.10024) arXiv preprint. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:PK3dFIQRxXsJ:scholar.google.com/&output=citation&scisdr=ClEwd-8QELrotZK-9wo:AFWwaeYAAAAAZQ247wo4GXoDnqP-_S51IozH5dE&scisig=AFWwaeYAAAAAZQ2471Un51ho87aYF2lSozOtdXU&scisf=4&ct=citation&cd=-1&hl=en). \*\*\* *[Best paper award](https://neurips2022.mlsafety.org/) — 2022 NeurIPS Machine Learning Safety Workshop* \*\*\*

Curmei, M., Haupt, A. A., Recht, B., & Hadfield-Menell, D. (2022, September). [Towards Psychologically-Grounded Dynamic Preference Models](https://dl.acm.org/doi/abs/10.1145/3523227.3546778). In Proceedings of the 16th ACM Conference on Recommender Systems (pp. 35-48). [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:WOxa2WDGuTcJ:scholar.google.com/&output=citation&scisdr=ClEwd-8QELrotZK-1vU:AFWwaeYAAAAAZQ24zvX7k5p1QSO-ZuVVpTqrMtk&scisig=AFWwaeYAAAAAZQ24zgTj6mA_XfKnu2CH7MTIJjQ&scisf=4&ct=citation&cd=-1&hl=en).

Räuker, T., Ho, A., Casper, S., & Hadfield-Menell, D. (2022). [Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks](https://arxiv.org/abs/2207.13243). SATML 2023. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:6IDnKqjNOrcJ:scholar.google.com/&output=citation&scisdr=CgUBYGTzEPyMg5PIZuc:AAGBfm0AAAAAYxjOfudLK6ychKhzX_GGjk7JydhRaQBs&scisig=AAGBfm0AAAAAYxjOfpUSteParaaZUb0Baq11kd8bT7oX&scisf=4&ct=citation&cd=-1&hl=en).

Casper, S., Hadfield-Menell, D., Kreiman, G (2022). [White-Box Adversarial Policies in Deep Reinforcement Learning](https://arxiv.org/abs/2209.02167). [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:Huc79PTJfakJ:scholar.google.com/&output=citation&scisdr=ClEwd-8QELrotZK-v9c:AFWwaeYAAAAAZQ24p9du_7iLiIbzO7OVFWqMLJg&scisig=AFWwaeYAAAAAZQ24p0MWHmdvsz6DeVY2L-1xMxk&scisf=4&ct=citation&cd=-1&hl=en).

Christoffersen, P.J.K., Haupt, A.A, Hadfield-Menell, D. (2022). [Get It in Writing: Formal Contracts Mitigate Social Dilemmas in Multi-Agent RL](https://arxiv.org/abs/2208.10469). [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:rctroivbpiAJ:scholar.google.com/&output=citation&scisdr=CgUBYGTzEPyMg5PIHNw:AAGBfm0AAAAAYxjOBNz2-vpDhjCI_wJ1FUgMgTwUEa8f&scisig=AAGBfm0AAAAAYxjOBPuUsEPypykSIeu3v7C_ZNMSKwx8&scisf=4&ct=citation&cd=-1&hl=en).

Yew, R.J. and Hadfield-Menell, D. (2022). [A Penalty Default Approach to Preemptive Harm Disclosure and Mitigation for AI Systems](https://dl.acm.org/doi/10.1145/3514094.3534130). In Proceedings of the 5th AAAI/ACM Conference on AI, Ethics, and Society. [BibTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:Zy8cJGbw9QUJ:scholar.google.com/&output=citation&scisdr=CgWTYX5AEPyMg45o47g:AAGBfm0AAAAAYwVu-7hfL7sgjbex8wF3U-g2nDKsY20o&scisig=AAGBfm0AAAAAYwVu-y80HvtCEX2eXNg2NM7Ki7kE-BiC&scisf=4&ct=citation&cd=-1&hl=en).

Casper, S., Nadeau, M., Hadfield-Menell, D, & Kreiman, G (2022). [Robust Feature-Level Adversaries are Interpretability Tools](https://arxiv.org/abs/2110.03605). Advances in Neural Information Processing Systems, 35, 33093-33106. [BibTeX](https://dblp.uni-trier.de/rec/journals/corr/abs-2110-03605.html?view=bibtex).


