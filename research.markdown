---
layout: default
permalink: /research/
---

{% include nav.html %}

## Research

Find us on [Github](https://github.com/Algorithmic-Alignment-Lab).

### 2022

Christoffersen, P.J.K., Haupt, A.A, Hadfield-Menell, D. (2022). [Get It in Writing: Formal Contracts Mitigate Social Dilemmas in Multi-Agent RL](https://arxiv.org/abs/2208.10469).

Yew, R.J. and Hadfield-Menell, D. (2022). [A Penalty Default Approach to Preemptive Harm Disclosure and Mitigation for AI Systems](https://dl.acm.org/doi/10.1145/3514094.3534130). In Proceedings of the 5th AAAI/ACM Conference on AI, Ethics, and Society. [BobTeX](https://scholar.googleusercontent.com/scholar.bib?q=info:Zy8cJGbw9QUJ:scholar.google.com/&output=citation&scisdr=CgWTYX5AEPyMg45o47g:AAGBfm0AAAAAYwVu-7hfL7sgjbex8wF3U-g2nDKsY20o&scisig=AAGBfm0AAAAAYwVu-y80HvtCEX2eXNg2NM7Ki7kE-BiC&scisf=4&ct=citation&cd=-1&hl=en)

Casper, S., Nadeau, M., Hadfield-Menell, D, & Kreiman, G (2022). [Robust Feature-Level Adversaries are Interpretability Tools](https://arxiv.org/abs/2110.03605). [BibTeX](https://dblp.uni-trier.de/rec/journals/corr/abs-2110-03605.html?view=bibtex)   


