<!DOCTYPE html>
<html lang="en-US">

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" type="text/css" media="screen" href="/assets/css/style.css?v=46a984be4b963cc5b853d7acbaa424cb4aeff05a">
    <link rel="shortcut icon" type="image/x-icon" href="favicon_io/favicon.ico">
<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Algorithmic Alignment Group | Researching frameworks for human-aligned AI @ MIT CSAIL.</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Algorithmic Alignment Group" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Researching frameworks for human-aligned AI @ MIT CSAIL." />
<meta property="og:description" content="Researching frameworks for human-aligned AI @ MIT CSAIL." />
<link rel="canonical" href="https://thestephencasper.github.io/team/" />
<meta property="og:url" content="https://thestephencasper.github.io/team/" />
<meta property="og:site_name" content="Algorithmic Alignment Group" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Algorithmic Alignment Group" />
<script type="application/ld+json">
{"headline":"Algorithmic Alignment Group","@type":"WebPage","url":"https://thestephencasper.github.io/team/","description":"Researching frameworks for human-aligned AI @ MIT CSAIL.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          
            <a id="forkme_banner" href="https://github.com/Algorithmic-Alignment-Lab/Algorithmic-Alignment-Lab.github.io">View on GitHub</a>
          

          <a href="/"><img style="float: left; padding-right: 20px; border: 0px;" src="/docs/assets/logo.png" width="68" height="68"></a><h1 id="project_title">Algorithmic Alignment Group</h1>
          <h3 id="project_tagline">Researching frameworks for human-aligned AI @ MIT CSAIL.</h3>

          
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        
<!--<h1>Group Name and Logo</h1>-->

<!--<head>-->
<!--    <meta charset="utf-8">-->
<!--    <link rel="stylesheet" href="_includes/styles.css">-->
<!--</head>-->

<center>
    <nav>
        <ul class="nav__links">
            <li><a href="/"><h3>Home</h3></a></li>
            <li><a href="/team/"><h3>Team</h3></a></li>
            <li><a href="/research/"><h3>Research</h3></a></li>
            <li><a href="/contact/"><h3>Contact</h3></a></li>
        </ul>
    </nav>
</center>

<h2 id="team">Team</h2>

<!--<img src="/docs/assets/sillhouette.jpeg" width="160" height="160" alt="Person 1 Name"> <p>Person 1, person1@gmail.com, website link<br>Bio goes here.</p>-->

<h3>Principal Investigator</h3>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/dylan.png" width="160" height="160" alt="Dylan Hadfield-Menell" />
    <strong>Dylan Hadfield-Menell</strong>, <a href="dhm@csail.mit.edu">dhm@csail.mit.edu</a>, <a href="http://people.csail.mit.edu/dhm/">Website</a>
    <br />
    Dylan is an assistant professor on the faculty of Artificial Intelligence and Decision-Making in the EECS Department and Computer Science and Artificial Intelligence Laboratory (CSAIL) at the Massachusetts Institute of Technology (MIT). His research focuses on the problem of agent alignment: the challenge of identifying behaviors that are consistent with the goals of another actor or group of actors. His work aims to identify algorithmic solutions to alignment problems that arise from groups of AI systems, principal-agent pairs (i.e., human-robot teams), and societal oversight of ML systems.
</p>

<h3>Ph.D Students</h3>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/andreas.png" width="160" height="160" alt="Andreas Haupt" />
    <strong>Andreas Haupt</strong>, <a href="haupt@csail.mit.edu">haupt@csail.mit.edu</a>, <a href="https://indraos.github.io/">Website</a>
    <br />
    Andy is an interdisciplinary Ph.D. Candidate with the Schwarzman College of Computing. He uses tools from Microeconomic Theory to understand multi-agent systems, recommendation engines, and automatic pricing tools in deployment and propose ways to mitigate undesirable consequences of seemingly innocuous algorithmic choices.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/jovana.jpg" width="160" height="160" alt="Jovana Kondic" />
    <strong>Jovana Kondic</strong>, <a href="jkondic@mit.edu">jkondic@mit.edu</a>, <a href="https://www.linkedin.com/in/jovanakondic/">LinkedIn</a>
    <br />
    Jovana's interests lie broadly at the intersection of probabilistic inference, social cognition, and human-robot interaction. Her research focuses on building interactive AI agents that 1) effectively learn from human input, and 2) understand and act in accordance with human preferences, intentions, and values.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/phillip.jpeg" width="160" height="160" alt="Phillip Christoffersen" />
    <strong>Phillip Christoffersen</strong>, <a href="philljkc@mit.edu">philljkc@mit.edu</a>, <a href="https://www.linkedin.com/in/phillip-christoffersen-393906140/">LinkedIn</a>
    <br />
    Phillip is broadly interested in reinforcement learning topics including AI alignment, neurosymbolic AI, and multi-agent RL. Before the Algorithmic Alignment Group, Phillip was an undergraduate researcher at the University of Toronto, advised by Prof. Sheila McIlraith. His main hobbies include reading, playing piano, and composing music.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/cas.webp" width="160" height="160" alt="Stephen Casper" />
    <strong>Stephen Casper</strong>, <a href="scasper@mit.edu">scasper@mit.edu</a>, <a href="https://stephencasper.com">Website</a>
    <br />
    Cas works on tools for trustworthy, safe AI. His research emphasizes interpretability, adversaries, and robust reinforcement learning. Before his Ph.D, he worked with the Harvard Kreiman Lab and the Center for Human-Compatible AI. He's also a member of the Effective Altruism community. Hobbies of his include biking, growing plants, and keeping insects.
</p>

<h3>Masters Students</h3>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/eunseo.jpeg" width="160" height="160" alt="Dana Choi" />
    <strong>Dana Choi</strong>, <a href="choie@mit.edu">choie@mit.edu</a>
    <br />
    Dana is broadly interested in understanding how the human normative system works and what enables cooperation. Through reverse-engineering the mechanisms of human collective intelligence, she hopes to contribute to efforts in designing and facilitating desirable interactions in our society. She draws insights from economics, anthropology, cognitive science, reinforcement learning, and social computing.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/olivia.jpg" width="160" height="160" alt="Olivia Siegel" />
    <strong>Olivia Siegel</strong>, <a href="osiegel@mit.edu">osiegel@mit.edu</a>, <a href="https://www.linkedin.com/in/olivia-siegel/">LinkedIn</a>
    <br />
    Olivia is a masters student interested in AI and robotics who gets most excited seeing algorithms come to life on physical robots. Prior to joining the Algorithmic Alignment group, she did her undergraduate at MIT in EECS and worked on soft robots in the Distributed Robotics Lab. Like any good New Englander, her hobbies include shellfishing, cycling, and maple syrup making.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/rjy.png" width="160" height="160" alt="Rui-Jie Yew" />
    <strong>Rui-Jie Yew</strong>, <a href="rjy@mit.edu">rjy@mit.edu</a>, <a href="https://r-jy.github.io/">Website</a>
    <br />
    Rui-Jie is an S.M. student in Technology and Policy doing research on regulatory mechanisms for AI. She is broadly interested in the societal impacts of AI and the organizational and policy incentives surrounding its development. Previously, she completed a joint BA in computer science and math from Scripps College as an off-campus major at Harvey Mudd.
</p>

<h3>Former Students</h3>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/me_smol.jpeg" width="160" height="160" alt="Magdalena Price" />
    <strong>Magdalena Price</strong>, <a href="maprice@mit.edu">maprice@mit.edu</a>
    <br />
    Lena is a first-year M-Eng student whose research focuses on human-computer interfaces and machine learning. Her current project is focused on making effective data preparation scalable and inexpensive, in the hopes of mitigating biased model results commonly seen in big data predictions.
</p>

<p>
    <img style="padding-right: 15px;" src="/docs/assets/max.png" width="160" height="160" alt="Max Langenkamp" />
    <strong>Max Langenkamp</strong>, <a href="maxnz@mit.edu">maxnz@mit.edu</a>
    <br />
    Max is researching AI governance. His current focus is on open source machine learning software and how it shapes AI research. He is especially inspired by the work of economist Elinor Ostrom and draws from fields ranging from the philosophy of science to the economics of innovation. Previously, he has researched computational cognitive science, worked at the White House Office of Science and Technology Policy, and published on AI policy at the Center for Security and Emerging Technology. He has a B.A. from MIT in computer science and loves bossa nova, Tibetan mythology and the history of technology.
</p>

<!--<br>-->
<!--<h4>Undergraduate Students</h4>-->


      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
<!--        -->
<!--        <p class="copyright">Algorithmic Alignment Group maintained by <a href="https://github.com/Algorithmic-Alignment-Lab">Algorithmic-Alignment-Lab</a></p>-->
<!--        -->
<!--        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>-->
      </footer>
    </div>
  </body>
</html>